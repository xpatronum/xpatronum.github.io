---
title: "What is IR?"
date: "2024-05-02 00:00:00 +0800"
categories: [learning]
tags: [nlp]
math: true
description: What is information retrieval in a nutshell
pin: true
---

Введем вспомогательные определения, которые будут использоваться в дальнейшем.

Запрос - это произвольная последовательность токенов, которая, как правило, составляет не более одного или двух предложений.

$$
\begin{equation}
    \label{eq:querydef}
    Q=\{t_1, t_2, \cdots t_l\}
\end{equation}
$$

Индекс - это коллекция документов, каждый из которых также представляет собой последовательность токенов, которая была предобработана таким образом, чтобы над осуществлять поиск.

$$
\begin{equation}
    \label{eq:indexdef}
    D=\{d_1, d_2, \cdots, d_N\}
\end{equation}
$$

Мы хотим подобрать такую функцию, которая смогла бы оперировать над объединенным пр-вом $Q$ и $D$ таким образом, чтобы возвращать релевантные документы $d_j \in D$, подходящие запросу $q_i$. Общее определение функции-поиска нужного документа в индексе с формальной точки зрения описывается следующим образом:

$$
\begin{equation}
    \label{eq:retrieverdef}
    R(q,D):Q\times D\mapsto\{d_1, d_2, \cdots, d_k\}
\end{equation}
$$

Где, с прикладной точки зрения, нужно выбрать очень маленькое подмножество всех проиндексированных документов $$ k << N $$. Параметр $k$ является гипер-параметром и, как правило, $$ k \in \{2, 3, 5, 10\} $$.

Спектр задач, в которых используется $R$ ($ \ref{eq:retrieverdef}$) - это фильтрация, поиск по описанию, поиск релевантных данных для LLM (e.g. RAG подход), и другие. На практике, широко распространены два подхода, моделирующих поиск - это нейронный поиск, где пространства $Q$ и $D$ отображаются в Евклидово $$ R^n $$, чтобы релевантным парам $$ \{q_i, d_j^{+}\} $$ соответствовали близкие в Евклидовом пр-ве вектора, а нерелевантным $$ \{q_i, d_j^{–}\} $$​ , соответственно, далекие.
